{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T11:09:40.454345100Z",
     "start_time": "2026-01-25T11:09:40.438458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "MASTER_FILE = \"draft_oracle_master_data.parquet\"\n",
    "FEATURE_FILE = \"draft_oracle_feature_store.parquet\"\n",
    "TRAIN_SET_FILE = \"draft_oracle_training_set.parquet\"\n",
    "MODEL_FILE = \"draft_oracle_brain.json\""
   ],
   "id": "45d5ceb5e75e405a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T11:09:40.464875100Z",
     "start_time": "2026-01-25T11:09:40.454345100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def enrich_combat_logic(df):\n",
    "    print(\"üß† Calculando L√≥gica de Combate (Damage Profile & Counters)...\")\n",
    "\n",
    "    sides = [\"blue\", \"red\"]\n",
    "\n",
    "    for side in sides:\n",
    "        # 1. SELECTORES H√çBRIDOS (Busca nombres viejos Y nuevos)\n",
    "        # Esto arregla el error: buscamos \"stat_magic_dmg\" O \"avg_magic_dmg\"\n",
    "        magic_cols = [c for c in df.columns if f\"{side}_\" in c and (\"stat_magic_dmg\" in c or \"avg_magic_dmg\" in c)]\n",
    "        phys_cols  = [c for c in df.columns if f\"{side}_\" in c and (\"stat_phys_dmg\" in c or \"avg_phys_dmg\" in c)]\n",
    "        # True damage tambi√©n suele ser avg_ ahora\n",
    "        true_cols  = [c for c in df.columns if f\"{side}_\" in c and (\"stat_true_dmg\" in c or \"avg_true_dmg\" in c)]\n",
    "\n",
    "        # Estos suelen mantener el nombre stat_\n",
    "        tank_cols  = [c for c in df.columns if f\"{side}_\" in c and \"stat_mitigated\" in c]\n",
    "        heal_cols  = [c for c in df.columns if f\"{side}_\" in c and \"stat_heal\" in c]\n",
    "        cc_cols    = [c for c in df.columns if f\"{side}_\" in c and \"stat_hard_cc\" in c]\n",
    "\n",
    "        # 2. SUMAS SEGURAS (Evita el ComputeError si la lista est√° vac√≠a)\n",
    "        # Si no hay columnas, sumamos 0 literal.\n",
    "        total_magic = pl.sum_horizontal(magic_cols) if magic_cols else pl.lit(0)\n",
    "        total_phys  = pl.sum_horizontal(phys_cols) if phys_cols else pl.lit(0)\n",
    "        total_true  = pl.sum_horizontal(true_cols) if true_cols else pl.lit(0)\n",
    "        total_tank  = pl.sum_horizontal(tank_cols) if tank_cols else pl.lit(0)\n",
    "        total_heal  = pl.sum_horizontal(heal_cols) if heal_cols else pl.lit(0)\n",
    "        total_cc    = pl.sum_horizontal(cc_cols) if cc_cols else pl.lit(0)\n",
    "\n",
    "        # Aplicamos al DataFrame\n",
    "        df = df.with_columns([\n",
    "            total_magic.fill_null(0).alias(f\"{side}_total_magic_dmg\"),\n",
    "            total_phys.fill_null(0).alias(f\"{side}_total_phys_dmg\"),\n",
    "            total_true.fill_null(0).alias(f\"{side}_total_true_dmg\"), # Nueva\n",
    "            total_tank.fill_null(0).alias(f\"{side}_total_tankiness\"),\n",
    "            total_heal.fill_null(0).alias(f\"{side}_total_sustain\"),\n",
    "            total_cc.fill_null(0).alias(f\"{side}_total_cc\")\n",
    "        ])\n",
    "\n",
    "        # 3. RATIOS\n",
    "        total_dmg = pl.col(f\"{side}_total_magic_dmg\") + pl.col(f\"{side}_total_phys_dmg\") + pl.col(f\"{side}_total_true_dmg\") + 1\n",
    "        df = df.with_columns(\n",
    "            (pl.col(f\"{side}_total_magic_dmg\") / total_dmg).alias(f\"{side}_magic_dmg_ratio\")\n",
    "        )\n",
    "\n",
    "    # 4. INTERACCIONES DE COUNTER (Anti-Tank & Anti-Heal)\n",
    "    df = df.with_columns([\n",
    "        # Shred Efficiency: (Da√±o M√°gico + True Damage) / Tanque Enemigo\n",
    "        ((pl.col(\"blue_total_magic_dmg\") + pl.col(\"blue_total_true_dmg\")) / (pl.col(\"red_total_tankiness\") + 1)).alias(\"blue_shred_efficiency\"),\n",
    "        ((pl.col(\"red_total_magic_dmg\") + pl.col(\"red_total_true_dmg\")) / (pl.col(\"blue_total_tankiness\") + 1)).alias(\"red_shred_efficiency\"),\n",
    "\n",
    "        # Anti-Sustain Burst: Da√±o Total / Sustain Enemigo\n",
    "        ((pl.col(\"blue_total_phys_dmg\") + pl.col(\"blue_total_magic_dmg\")) / (pl.col(\"red_total_sustain\") + 1000)).alias(\"blue_anti_sustain_burst\"),\n",
    "        ((pl.col(\"red_total_phys_dmg\") + pl.col(\"red_total_magic_dmg\")) / (pl.col(\"blue_total_sustain\") + 1000)).alias(\"red_anti_sustain_burst\")\n",
    "    ])\n",
    "\n",
    "    blue_volatility = sum([pl.col(f\"blue_{role}_var_gold_volatility\").fill_null(0) for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "    red_volatility  = sum([pl.col(f\"red_{role}_var_gold_volatility\").fill_null(0)  for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (blue_volatility - red_volatility).alias(\"diff_team_volatility\")\n",
    "    )\n",
    "\n",
    "    return df"
   ],
   "id": "e9ca457788af9bf6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T11:09:44.611701900Z",
     "start_time": "2026-01-25T11:09:40.464875100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assemble_and_clean_dataset_ultimate():\n",
    "    print(\"üèóÔ∏è  REGENERANDO DATASET V4.2 (Incluyendo Risk & Volatility)...\")\n",
    "\n",
    "    # 1. Cargar Embeddings\n",
    "    df_features = pl.read_parquet(FEATURE_FILE)\n",
    "\n",
    "    # 2. Cargar Partidas\n",
    "    master_full = pl.read_parquet(MASTER_FILE)\n",
    "    df_matches = master_full.select([\n",
    "        \"game_id\", \"region\", \"patch\", \"duration\", \"target\",\n",
    "        \"champ_id\", \"position\", \"side\"\n",
    "    ])\n",
    "    del master_full\n",
    "    gc.collect()\n",
    "\n",
    "    # 3. ENRIQUECIMIENTO\n",
    "    print(\"   üîó Pegando Stats + Estilos + Riesgo...\")\n",
    "    enriched = df_matches.join(\n",
    "        df_features,\n",
    "        on=[\"champ_id\", \"position\", \"region\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 4. PIVOTADO\n",
    "    print(\"   üîÑ Pivotando a formato Wide...\")\n",
    "\n",
    "    enriched = enriched.with_columns([\n",
    "        pl.when(pl.col(\"side\") == 100).then(pl.lit(\"blue\")).otherwise(pl.lit(\"red\")).alias(\"side_str\")\n",
    "    ])\n",
    "    enriched = enriched.with_columns(\n",
    "        (pl.col(\"side_str\") + \"_\" + pl.col(\"position\")).alias(\"pivot_col\")\n",
    "    )\n",
    "\n",
    "    # --- CORRECCI√ìN V4.2: A√ëADIMOS \"var_\" AL FILTRO ---\n",
    "    cols_to_pivot = [\n",
    "        c for c in df_features.columns\n",
    "        if c.startswith(\"stat_\")\n",
    "        or c.startswith(\"avg_\")\n",
    "        or c.startswith(\"z_style_\")\n",
    "        or c.startswith(\"var_\") # <--- ¬°AQU√ç EST√Å LA CLAVE!\n",
    "    ]\n",
    "    cols_to_pivot.append(\"champ_id\")\n",
    "\n",
    "    wide_df = enriched.pivot(\n",
    "        values=cols_to_pivot,\n",
    "        index=[\"game_id\", \"target\", \"region\", \"patch\"],\n",
    "        columns=\"pivot_col\",\n",
    "        aggregate_function=\"first\"\n",
    "    )\n",
    "\n",
    "    # 5. RENOMBRADO\n",
    "    print(\"   üè∑Ô∏è  Normalizando nombres...\")\n",
    "    new_names = {}\n",
    "    for col in wide_df.columns:\n",
    "        if \"blue\" in col or \"red\" in col:\n",
    "            parts = col.split(\"_\")\n",
    "            if \"blue\" in parts:\n",
    "                idx = parts.index(\"blue\")\n",
    "                team_pos = f\"{parts[idx]}_{parts[idx+1]}\"\n",
    "                stat_parts = [p for i, p in enumerate(parts) if i != idx and i != idx+1]\n",
    "                stat_name = \"_\".join(stat_parts)\n",
    "                new_names[col] = f\"{team_pos}_{stat_name}\"\n",
    "            elif \"red\" in parts:\n",
    "                idx = parts.index(\"red\")\n",
    "                team_pos = f\"{parts[idx]}_{parts[idx+1]}\"\n",
    "                stat_parts = [p for i, p in enumerate(parts) if i != idx and i != idx+1]\n",
    "                stat_name = \"_\".join(stat_parts)\n",
    "                new_names[col] = f\"{team_pos}_{stat_name}\"\n",
    "\n",
    "    wide_df = wide_df.rename(new_names)\n",
    "\n",
    "    print(f\"   üíæ Dataset V4.2 Guardado: {wide_df.shape}\")\n",
    "    wide_df.write_parquet(TRAIN_SET_FILE)\n",
    "    return wide_df\n",
    "\n",
    "# ¬°EJECUTA ESTO AHORA!\n",
    "df = assemble_and_clean_dataset_ultimate()"
   ],
   "id": "1fc132fb4b451638",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è  REGENERANDO DATASET V4.2 (Incluyendo Risk & Volatility)...\n",
      "   üîó Pegando Stats + Estilos + Riesgo...\n",
      "   üîÑ Pivotando a formato Wide...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lapto\\AppData\\Local\\Temp\\ipykernel_20160\\4060532075.py:44: DeprecationWarning: the argument `columns` for `DataFrame.pivot` is deprecated. It was renamed to `on` in version 1.0.0.\n",
      "  wide_df = enriched.pivot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üè∑Ô∏è  Normalizando nombres...\n",
      "   üíæ Dataset V4.2 Guardado: (585778, 268)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T11:09:47.968790900Z",
     "start_time": "2026-01-25T11:09:44.635630200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_interaction_matrices(df_master):\n",
    "    \"\"\"\n",
    "    Genera matrices de conocimiento: Sinergias y Counters.\n",
    "    \"\"\"\n",
    "    print(\"üß† Construyendo Cerebro T√°ctico (Sinergias y Counters)...\")\n",
    "\n",
    "    # --- CORRECCI√ìN AQU√ç: Usamos \"target\" y lo renombramos a \"win\" ---\n",
    "    matches = df_master.lazy().select([\n",
    "        \"game_id\", \"side\", \"champ_id\", \"position\",\n",
    "        pl.col(\"target\").alias(\"win\") # <--- EL CAMBIO CR√çTICO\n",
    "    ])\n",
    "\n",
    "    # --- 1. MATRIZ DE SINERGIA (Aliados) ---\n",
    "    print(\"   -> Calculando pares de aliados ganadores...\")\n",
    "    synergy = (\n",
    "        matches.join(matches, on=[\"game_id\", \"side\"])\n",
    "        .filter(pl.col(\"champ_id\") != pl.col(\"champ_id_right\"))\n",
    "        .group_by([\"champ_id\", \"champ_id_right\"])\n",
    "        .agg([\n",
    "            pl.col(\"win\").mean().alias(\"syn_winrate\"),\n",
    "            pl.count().alias(\"matches\")\n",
    "        ])\n",
    "        .filter(pl.col(\"matches\") > 50)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    # --- 2. MATRIZ DE COUNTER (Enemigos) ---\n",
    "    print(\"   -> Calculando matchups directos...\")\n",
    "    counters = (\n",
    "        matches.join(matches, on=\"game_id\")\n",
    "        .filter(pl.col(\"side\") != pl.col(\"side_right\"))\n",
    "        .filter(pl.col(\"position\") == pl.col(\"position_right\")) # Lane vs Lane\n",
    "        .group_by([\"champ_id\", \"champ_id_right\"])\n",
    "        .agg([\n",
    "            pl.col(\"win\").mean().alias(\"counter_winrate\"),\n",
    "            pl.count().alias(\"matches\")\n",
    "        ])\n",
    "        .filter(pl.col(\"matches\") > 50)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    return synergy, counters\n",
    "\n",
    "def assemble_and_clean_dataset_ultimate():\n",
    "    print(\"üèóÔ∏è  REGENERANDO DATASET V4.3 (FIX DEFINITIVO)...\")\n",
    "\n",
    "    # 1. Cargar Embeddings\n",
    "    df_features = pl.read_parquet(FEATURE_FILE)\n",
    "\n",
    "    # 2. Cargar Partidas\n",
    "    master_full = pl.read_parquet(MASTER_FILE)\n",
    "    df_matches = master_full.select([\n",
    "        \"game_id\", \"region\", \"patch\", \"duration\", \"target\",\n",
    "        \"champ_id\", \"position\", \"side\"\n",
    "    ])\n",
    "    del master_full\n",
    "    gc.collect()\n",
    "\n",
    "    # 3. ENRIQUECIMIENTO\n",
    "    print(\"   üîó Pegando Todo el ADN...\")\n",
    "    enriched = df_matches.join(\n",
    "        df_features,\n",
    "        on=[\"champ_id\", \"position\", \"region\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 4. PIVOTADO\n",
    "    print(\"   üîÑ Pivotando a formato Wide...\")\n",
    "\n",
    "    enriched = enriched.with_columns([\n",
    "        pl.when(pl.col(\"side\") == 100).then(pl.lit(\"blue\")).otherwise(pl.lit(\"red\")).alias(\"side_str\")\n",
    "    ])\n",
    "    enriched = enriched.with_columns(\n",
    "        (pl.col(\"side_str\") + \"_\" + pl.col(\"position\")).alias(\"pivot_col\")\n",
    "    )\n",
    "\n",
    "    # --- EL FILTRO CORREGIDO ---\n",
    "    # Aseg√∫rate de que \"var_\" est√° aqu√≠\n",
    "    cols_to_pivot = [\n",
    "        c for c in df_features.columns\n",
    "        if c.startswith(\"stat_\")\n",
    "        or c.startswith(\"avg_\")\n",
    "        or c.startswith(\"z_style_\")\n",
    "        or c.startswith(\"var_\") # <--- ¬°ESTO ES LO QUE FALTABA!\n",
    "    ]\n",
    "    cols_to_pivot.append(\"champ_id\")\n",
    "\n",
    "    wide_df = enriched.pivot(\n",
    "        values=cols_to_pivot,\n",
    "        index=[\"game_id\", \"target\", \"region\", \"patch\"],\n",
    "        columns=\"pivot_col\",\n",
    "        aggregate_function=\"first\"\n",
    "    )\n",
    "\n",
    "    # 5. RENOMBRADO\n",
    "    print(\"   üè∑Ô∏è  Normalizando nombres...\")\n",
    "    new_names = {}\n",
    "    for col in wide_df.columns:\n",
    "        if \"blue\" in col or \"red\" in col:\n",
    "            parts = col.split(\"_\")\n",
    "            if \"blue\" in parts:\n",
    "                idx = parts.index(\"blue\")\n",
    "                team_pos = f\"{parts[idx]}_{parts[idx+1]}\"\n",
    "                stat_parts = [p for i, p in enumerate(parts) if i != idx and i != idx+1]\n",
    "                stat_name = \"_\".join(stat_parts)\n",
    "                new_names[col] = f\"{team_pos}_{stat_name}\"\n",
    "            elif \"red\" in parts:\n",
    "                idx = parts.index(\"red\")\n",
    "                team_pos = f\"{parts[idx]}_{parts[idx+1]}\"\n",
    "                stat_parts = [p for i, p in enumerate(parts) if i != idx and i != idx+1]\n",
    "                stat_name = \"_\".join(stat_parts)\n",
    "                new_names[col] = f\"{team_pos}_{stat_name}\"\n",
    "\n",
    "    wide_df = wide_df.rename(new_names)\n",
    "\n",
    "    print(f\"   üíæ Dataset V4.3 Guardado: {wide_df.shape}\")\n",
    "    wide_df.write_parquet(TRAIN_SET_FILE)\n",
    "    return wide_df\n",
    "\n",
    "# ¬°EJECUTA ESTO AHORA!\n",
    "df = assemble_and_clean_dataset_ultimate()"
   ],
   "id": "818c19c27d6c84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è  REGENERANDO DATASET V4.3 (FIX DEFINITIVO)...\n",
      "   üîó Pegando Todo el ADN...\n",
      "   üîÑ Pivotando a formato Wide...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lapto\\AppData\\Local\\Temp\\ipykernel_20160\\86439542.py:88: DeprecationWarning: the argument `columns` for `DataFrame.pivot` is deprecated. It was renamed to `on` in version 1.0.0.\n",
      "  wide_df = enriched.pivot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üè∑Ô∏è  Normalizando nombres...\n",
      "   üíæ Dataset V4.3 Guardado: (585778, 268)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-25T11:09:47.992107300Z",
     "start_time": "2026-01-25T11:09:47.979961100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def enrich_critical_synergies(df):\n",
    "    print(\"üï∏Ô∏è Tejiendo la Red de Sinergias Cr√≠ticas (Graph Theory)...\")\n",
    "\n",
    "    # 1. Cargar Matriz de Sinergia\n",
    "    try:\n",
    "        synergy_matrix = pl.read_parquet(\"draft_oracle_synergy_matrix.parquet\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è No se encontr√≥ la matriz de sinergia. Saltando paso de grafos.\")\n",
    "        return df\n",
    "\n",
    "    # Parejas cr√≠ticas\n",
    "    critical_pairs = [\n",
    "        (\"MIDDLE\", \"JUNGLE\", \"syn_mid_jg\"),\n",
    "        (\"BOTTOM\", \"UTILITY\", \"syn_bot_duo\"),\n",
    "        (\"TOP\", \"JUNGLE\", \"syn_top_jg\"),\n",
    "    ]\n",
    "\n",
    "    sides = [\"blue\", \"red\"]\n",
    "\n",
    "    for side in sides:\n",
    "        for role1, role2, feat_name in critical_pairs:\n",
    "            col_id1 = f\"{side}_{role1}_champ_id\"\n",
    "            col_id2 = f\"{side}_{role2}_champ_id\"\n",
    "\n",
    "            # Verificaci√≥n de seguridad: Si no existen las columnas de ID, saltamos\n",
    "            if col_id1 not in df.columns or col_id2 not in df.columns:\n",
    "                continue\n",
    "\n",
    "            temp_syn = synergy_matrix.select([\n",
    "                pl.col(\"champ_id\").alias(col_id1),\n",
    "                pl.col(\"champ_id_right\").alias(col_id2),\n",
    "                pl.col(\"syn_winrate\").alias(f\"{side}_{feat_name}\")\n",
    "            ])\n",
    "\n",
    "            df = df.join(temp_syn, on=[col_id1, col_id2], how=\"left\")\n",
    "            df = df.with_columns(pl.col(f\"{side}_{feat_name}\").fill_null(0.5))\n",
    "\n",
    "    # 2. GAPS (Diferencias entre equipos)\n",
    "    if \"blue_syn_bot_duo\" in df.columns and \"red_syn_bot_duo\" in df.columns:\n",
    "        df = df.with_columns((pl.col(\"blue_syn_bot_duo\") - pl.col(\"red_syn_bot_duo\")).alias(\"gap_syn_bot_duo\"))\n",
    "    if \"blue_syn_mid_jg\" in df.columns and \"red_syn_mid_jg\" in df.columns:\n",
    "        df = df.with_columns((pl.col(\"blue_syn_mid_jg\") - pl.col(\"red_syn_mid_jg\")).alias(\"gap_syn_mid_jg\"))\n",
    "\n",
    "    return df\n"
   ],
   "id": "3cbe1ea4c54315eb",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-25T11:24:26.500887Z",
     "start_time": "2026-01-25T11:09:47.992107300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. CARGA Y ENSAMBLAJE DE DATOS ---\n",
    "def load_and_prep_data():\n",
    "    import os\n",
    "    if os.path.exists(TRAIN_SET_FILE):\n",
    "        print(f\"‚ö° Cargando dataset pre-cocinado: {TRAIN_SET_FILE}\")\n",
    "        df = pl.read_parquet(TRAIN_SET_FILE)\n",
    "    else:\n",
    "        # Si no existe, lanza error o pega aqu√≠ tu c√≥digo de pivotado anterior\n",
    "        raise FileNotFoundError(\"Genera primero el training_set con el c√≥digo anterior.\")\n",
    "\n",
    "    print(\"üëî Aplicando L√≥gica de Head Coach (Archetypes & Synergies)...\")\n",
    "\n",
    "    # Definimos columnas por equipo\n",
    "    sides = [\"blue\", \"red\"]\n",
    "    new_cols = []\n",
    "\n",
    "    for side in sides:\n",
    "        enemy_side = \"red\" if side == \"blue\" else \"blue\"\n",
    "\n",
    "        # --- SELECTORES DE COLUMNAS ---\n",
    "        # Da√±o y Aguante\n",
    "        dmg_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_dpm\" in c]\n",
    "        mitigated_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_mitigated\" in c]\n",
    "        heal_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_heal\" in c]\n",
    "\n",
    "        # Control\n",
    "        cc_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_hard_cc\" in c]\n",
    "        vision_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_vision\" in c]\n",
    "\n",
    "        # Posiciones Espec√≠ficas (Para Sinergia Mid-Jungle)\n",
    "        mid_roam = f\"{side}_middle_stat_roam_kills\"\n",
    "        jg_roam = f\"{side}_jungle_stat_roam_kills\"\n",
    "\n",
    "        # --- ARQUETIPO 1: ENGAGE POTENTIAL (Hard Engage) ---\n",
    "        # Mucho CC + Mucho Aguante (Tanques que se tiran)\n",
    "        # F√≥rmula: (Total CC * Total Mitigado) / 1000\n",
    "        team_cc = pl.sum_horizontal(cc_cols)\n",
    "        team_tankiness = pl.sum_horizontal(mitigated_cols)\n",
    "        engage_score = ((team_cc * team_tankiness) / 10000).alias(f\"{side}_archetype_engage\")\n",
    "        new_cols.append(engage_score)\n",
    "\n",
    "        # --- ARQUETIPO 2: SUSTAIN / PEEL (Protect the Carry) ---\n",
    "        # Muchas curaciones + Escudos\n",
    "        sustain_score = (pl.sum_horizontal(heal_cols) + team_tankiness).alias(f\"{side}_archetype_sustain\")\n",
    "        new_cols.append(sustain_score)\n",
    "\n",
    "        # --- ARQUETIPO 3: PICK POTENTIAL (Vision Control) ---\n",
    "        # Si ves al enemigo antes, lo matas. Visi√≥n + CC.\n",
    "        vision_score = pl.sum_horizontal(vision_cols)\n",
    "        pick_potential = (vision_score * team_cc).alias(f\"{side}_archetype_pick\")\n",
    "        new_cols.append(pick_potential)\n",
    "\n",
    "        # --- SINERGIA PRO: 2v2 MID-JUNGLE ---\n",
    "        # Sumamos la capacidad de roameo de Mid y Jungla\n",
    "        if mid_roam in df.columns and jg_roam in df.columns:\n",
    "            mid_jg_syn = (pl.col(mid_roam) + pl.col(jg_roam)).alias(f\"{side}_syn_mid_jungle\")\n",
    "            new_cols.append(mid_jg_syn)\n",
    "\n",
    "        prio_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_lane_priority_score\" in c]\n",
    "        rel_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_reliability_index\" in c]\n",
    "        early_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_wr_early\" in c]\n",
    "        late_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_wr_late\" in c]\n",
    "\n",
    "        # Validamos que existan antes de sumar (evita el ComputeError)\n",
    "        if len(prio_cols) > 0:\n",
    "            # A. Lane Kingdom (Prioridad Total)\n",
    "            new_cols.append(pl.sum_horizontal(prio_cols).alias(f\"{side}_strat_total_priority\"))\n",
    "\n",
    "            # B. Reliability (Consistencia)\n",
    "            new_cols.append(pl.mean_horizontal(rel_cols).alias(f\"{side}_strat_avg_reliability\"))\n",
    "\n",
    "            # C. Tempo (Power Spikes)\n",
    "            new_cols.append(pl.mean_horizontal(early_cols).alias(f\"{side}_strat_early_power\"))\n",
    "            new_cols.append(pl.mean_horizontal(late_cols).alias(f\"{side}_strat_late_power\"))\n",
    "\n",
    "    # --- CROSS-TEAM FEATURES (La diferencia entre equipos) ---\n",
    "    # Esto es vital: XGBoost aprende mejor de \"Diferencias\" que de n√∫meros absolutos\n",
    "    # Ej: No importa si tengo 100 de CC, importa si tengo M√ÅS CC que el enemigo.\n",
    "\n",
    "    # Pre-calculamos sumas temporales\n",
    "    blue_cc = pl.sum_horizontal([c for c in df.columns if \"blue_\" in c and \"stat_hard_cc\" in c])\n",
    "    red_cc = pl.sum_horizontal([c for c in df.columns if \"red_\" in c and \"stat_hard_cc\" in c])\n",
    "\n",
    "    blue_range = pl.sum_horizontal([c for c in df.columns if \"blue_\" in c and \"stat_dpm\" in c])\n",
    "    red_mitigation = pl.sum_horizontal([c for c in df.columns if \"red_\" in c and \"stat_mitigated\" in c])\n",
    "\n",
    "    # 1. CC DIFF (¬øQui√©n controla la pelea?)\n",
    "    new_cols.append((blue_cc - red_cc).alias(\"diff_cc_gap\"))\n",
    "\n",
    "    # 2. DAMAGE vs TANKINESS (¬øPueden bajarse a nuestros tanques?)\n",
    "    # Ratio: Nuestro Da√±o / Su Aguante\n",
    "    new_cols.append((blue_range / (red_mitigation + 1)).alias(\"diff_shred_potential\"))\n",
    "\n",
    "    # Aplicar todo\n",
    "    df = df.with_columns(new_cols)\n",
    "    return df\n",
    "\n",
    "# 1. CARGA\n",
    "if 'load_and_prep_data' not in globals(): raise Exception(\"Ejecuta load_and_prep_data()\")\n",
    "print(\"‚ö° Cargando dataset...\")\n",
    "df = load_and_prep_data()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CAPA 1: INTELIGENCIA DE COMBATE (Da√±o, Tanques, Burst)\n",
    "# ---------------------------------------------------------\n",
    "def enrich_combat_logic(df):\n",
    "    print(\"üß† [1/3] Calculando L√≥gica de Combate (Da√±o vs Resistencia)...\")\n",
    "    sides = [\"blue\", \"red\"]\n",
    "    for side in sides:\n",
    "        # Selectores\n",
    "        magic_cols = [c for c in df.columns if f\"{side}_\" in c and (\"stat_magic_dmg\" in c or \"avg_magic_dmg\" in c)]\n",
    "        phys_cols  = [c for c in df.columns if f\"{side}_\" in c and (\"stat_phys_dmg\" in c or \"avg_phys_dmg\" in c)]\n",
    "        true_cols  = [c for c in df.columns if f\"{side}_\" in c and (\"stat_true_dmg\" in c or \"avg_true_dmg\" in c)]\n",
    "        tank_cols  = [c for c in df.columns if f\"{side}_\" in c and \"stat_mitigated\" in c]\n",
    "        heal_cols  = [c for c in df.columns if f\"{side}_\" in c and \"stat_heal\" in c]\n",
    "        cc_cols    = [c for c in df.columns if f\"{side}_\" in c and \"stat_hard_cc\" in c]\n",
    "\n",
    "        # Sumas Seguras\n",
    "        total_magic = pl.sum_horizontal(magic_cols) if magic_cols else pl.lit(0)\n",
    "        total_phys  = pl.sum_horizontal(phys_cols) if phys_cols else pl.lit(0)\n",
    "        total_true  = pl.sum_horizontal(true_cols) if true_cols else pl.lit(0)\n",
    "        total_tank  = pl.sum_horizontal(tank_cols) if tank_cols else pl.lit(0)\n",
    "        total_heal  = pl.sum_horizontal(heal_cols) if heal_cols else pl.lit(0)\n",
    "        total_cc    = pl.sum_horizontal(cc_cols) if cc_cols else pl.lit(0)\n",
    "\n",
    "        # --- CORRECCI√ìN AQU√ç: Quitada la asignaci√≥n 'total_sustain =' ---\n",
    "        df = df.with_columns([\n",
    "            total_magic.fill_null(0).alias(f\"{side}_total_magic_dmg\"),\n",
    "            total_phys.fill_null(0).alias(f\"{side}_total_phys_dmg\"),\n",
    "            total_true.fill_null(0).alias(f\"{side}_total_true_dmg\"),\n",
    "            total_tank.fill_null(0).alias(f\"{side}_total_tankiness\"),\n",
    "            total_heal.fill_null(0).alias(f\"{side}_total_sustain\"),\n",
    "            total_cc.fill_null(0).alias(f\"{side}_total_cc\")\n",
    "        ])\n",
    "\n",
    "        # Ratios\n",
    "        total_dmg = pl.col(f\"{side}_total_magic_dmg\") + pl.col(f\"{side}_total_phys_dmg\") + pl.col(f\"{side}_total_true_dmg\") + 1\n",
    "        df = df.with_columns((pl.col(f\"{side}_total_magic_dmg\") / total_dmg).alias(f\"{side}_magic_dmg_ratio\"))\n",
    "\n",
    "    df = df.with_columns([\n",
    "        ((pl.col(\"blue_total_magic_dmg\") + pl.col(\"blue_total_true_dmg\")) / (pl.col(\"red_total_tankiness\") + 1)).alias(\"blue_shred_efficiency\"),\n",
    "        ((pl.col(\"red_total_magic_dmg\") + pl.col(\"red_total_true_dmg\")) / (pl.col(\"blue_total_tankiness\") + 1)).alias(\"red_shred_efficiency\"),\n",
    "        ((pl.col(\"blue_total_phys_dmg\") + pl.col(\"blue_total_magic_dmg\")) / (pl.col(\"red_total_sustain\") + 1000)).alias(\"blue_anti_sustain_burst\"),\n",
    "        ((pl.col(\"red_total_phys_dmg\") + pl.col(\"red_total_magic_dmg\")) / (pl.col(\"blue_total_sustain\") + 1000)).alias(\"red_anti_sustain_burst\")\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "def enrich_behavioral_strategy(df):\n",
    "    print(\"üî¨ [2/3] Analizando Psicolog√≠a, Econom√≠a y RIESGO (V12)...\")\n",
    "    sides = [\"blue\", \"red\"]\n",
    "    for side in sides:\n",
    "        # Sinergia de Gankeo\n",
    "        jg_aggro = pl.col(f\"{side}_JUNGLE_z_style_gank_heaviness\").fill_null(0)\n",
    "        lanes_aggro = (pl.col(f\"{side}_TOP_z_style_lane_dominance\").fill_null(0) +\n",
    "                       pl.col(f\"{side}_MIDDLE_z_style_lane_dominance\").fill_null(0) +\n",
    "                       pl.col(f\"{side}_BOTTOM_z_style_lane_dominance\").fill_null(0)) / 3\n",
    "        df = df.with_columns((jg_aggro * lanes_aggro).alias(f\"{side}_strat_gank_compatibility\"))\n",
    "\n",
    "        # Fricci√≥n de Recursos\n",
    "        gold_hunger = sum([pl.col(f\"{side}_{role}_z_style_gold_hunger\").fill_null(0)\n",
    "                           for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "        df = df.with_columns(gold_hunger.alias(f\"{side}_strat_resource_friction\"))\n",
    "\n",
    "        # Invasi√≥n\n",
    "        invade_potential = pl.col(f\"{side}_JUNGLE_z_style_invade_pressure\").fill_null(0)\n",
    "        backup_potential = (pl.col(f\"{side}_TOP_z_style_roaming_tendency\").fill_null(0) + pl.col(f\"{side}_MIDDLE_z_style_roaming_tendency\").fill_null(0))\n",
    "        df = df.with_columns((invade_potential * backup_potential).alias(f\"{side}_strat_invade_safety\"))\n",
    "\n",
    "    # RIESGO DE COMPOSICI√ìN (V12)\n",
    "    try:\n",
    "        blue_vol = sum([pl.col(f\"blue_{role}_var_gold_volatility\").fill_null(0) for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "        red_vol  = sum([pl.col(f\"red_{role}_var_gold_volatility\").fill_null(0)  for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "        df = df.with_columns((blue_vol - red_vol).alias(\"diff_team_volatility\"))\n",
    "        print(\"   ‚úÖ Variable de Volatilidad (Riesgo) Calculada.\")\n",
    "    except:\n",
    "        print(\"   ‚ö†Ô∏è No se encontraron columnas de Volatilidad. Se entrena sin factor de riesgo.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def enrich_critical_synergies(df):\n",
    "    print(\"üï∏Ô∏è  [3/3] Tejiendo Grafos de Sinergia (Mid-Jungle Links)...\")\n",
    "    try:\n",
    "        synergy_matrix = pl.read_parquet(\"draft_oracle_synergy_matrix.parquet\")\n",
    "    except:\n",
    "        print(\"   ‚ö†Ô∏è No se encontr√≥ la matriz de sinergia.\")\n",
    "        return df\n",
    "\n",
    "    critical_pairs = [(\"MIDDLE\", \"JUNGLE\", \"syn_mid_jg\"), (\"BOTTOM\", \"UTILITY\", \"syn_bot_duo\"), (\"TOP\", \"JUNGLE\", \"syn_top_jg\")]\n",
    "    sides = [\"blue\", \"red\"]\n",
    "\n",
    "    for side in sides:\n",
    "        for role1, role2, feat_name in critical_pairs:\n",
    "            col_id1 = f\"{side}_{role1}_champ_id\"\n",
    "            col_id2 = f\"{side}_{role2}_champ_id\"\n",
    "            if col_id1 not in df.columns or col_id2 not in df.columns: continue\n",
    "\n",
    "            temp_syn = synergy_matrix.select([\n",
    "                pl.col(\"champ_id\").alias(col_id1), pl.col(\"champ_id_right\").alias(col_id2), pl.col(\"syn_winrate\").alias(f\"{side}_{feat_name}\")\n",
    "            ])\n",
    "            df = df.join(temp_syn, on=[col_id1, col_id2], how=\"left\")\n",
    "            df = df.with_columns(pl.col(f\"{side}_{feat_name}\").fill_null(0.5))\n",
    "\n",
    "    if \"blue_syn_mid_jg\" in df.columns and \"red_syn_mid_jg\" in df.columns:\n",
    "        df = df.with_columns((pl.col(\"blue_syn_mid_jg\") - pl.col(\"red_syn_mid_jg\")).alias(\"gap_syn_mid_jg\"))\n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. CARGA Y EJECUCI√ìN\n",
    "# ==============================================================================\n",
    "TRAIN_FILE = \"draft_oracle_training_set.parquet\"\n",
    "print(f\"‚ö° Cargando Dataset desde {TRAIN_FILE}...\")\n",
    "\n",
    "if not os.path.exists(TRAIN_FILE):\n",
    "    raise FileNotFoundError(\"Ejecuta primero el Assembler.\")\n",
    "\n",
    "# Cargar y convertir a Float32 inmediatamente para ahorrar 50% de RAM\n",
    "df = pl.read_parquet(TRAIN_FILE)\n",
    "float_cols = [c for c in df.columns if df[c].dtype == pl.Float64]\n",
    "if float_cols:\n",
    "    print(\"üìâ Comprimiendo datos a Float32...\")\n",
    "    df = df.with_columns([pl.col(c).cast(pl.Float32) for c in float_cols])\n",
    "\n",
    "# --- APLICAR ENRIQUECIMIENTO (Si no est√°n ya) ---\n",
    "# Nota: Si ya lo ejecutaste antes y guardaste, esto puede sobrar, pero por seguridad:\n",
    "if 'enrich_combat_logic' in globals(): df = enrich_combat_logic(df)\n",
    "if 'enrich_behavioral_strategy' in globals(): df = enrich_behavioral_strategy(df)\n",
    "if 'enrich_critical_synergies' in globals(): df = enrich_critical_synergies(df)\n",
    "\n",
    "# Duelos\n",
    "roles = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]\n",
    "duel_stats = [\"stat_winrate\", \"stat_gpm\", \"stat_dpm\", \"z_style_lane_dominance\"]\n",
    "new_cols = []\n",
    "for role in roles:\n",
    "    for stat in duel_stats:\n",
    "        col_blue, col_red = f\"blue_{role}_{stat}\", f\"red_{role}_{stat}\"\n",
    "        if col_blue in df.columns and col_red in df.columns:\n",
    "            new_cols.append((pl.col(col_blue) - pl.col(col_red)).alias(f\"duel_{role}_{stat}\"))\n",
    "if new_cols: df = df.with_columns(new_cols)\n",
    "\n",
    "# 2. FILTRADO Y LIMPIEZA\n",
    "feature_cols = [c for c in df.columns if (\n",
    "    \"stat_\" in c or \"rune_\" in c or \"archetype_\" in c or \"gap_\" in c or \"duel_\" in c or\n",
    "    \"_total_\" in c or \"_ratio\" in c or \"_efficiency\" in c or \"_burst\" in c or\n",
    "    \"z_style_\" in c or \"_strat_\" in c or \"_syn_\" in c or \"diff_team_volatility\" in c\n",
    ") and c not in [\"target\", \"split_key\", \"game_id\"] and \"win\" not in c]\n",
    "\n",
    "print(f\"üìä Features Totales: {len(feature_cols)}\")\n",
    "\n",
    "# 3. GENERACI√ìN DE MATRICES (USANDO DMatrix CL√ÅSICA)\n",
    "print(\"‚úÇÔ∏è  Dividiendo Train/Test...\")\n",
    "df = df.with_columns(pl.Series(name=\"split_key\", values=np.random.rand(df.height)).cast(pl.Float32))\n",
    "\n",
    "# Extraemos numpy arrays directos para evitar copias extra de Polars\n",
    "X_train = df.filter(pl.col(\"split_key\") < 0.95).select(feature_cols).to_numpy()\n",
    "y_train = df.filter(pl.col(\"split_key\") < 0.95).select(\"target\").to_numpy().flatten()\n",
    "X_test  = df.filter(pl.col(\"split_key\") >= 0.95).select(feature_cols).to_numpy()\n",
    "y_test  = df.filter(pl.col(\"split_key\") >= 0.95).select(\"target\").to_numpy().flatten()\n",
    "\n",
    "print(f\"   -> Liberando memoria del DataFrame ({df.estimated_size() / 1024**2:.2f} MB)...\")\n",
    "del df\n",
    "gc.collect() # ¬°CR√çTICO!\n",
    "\n",
    "print(\"‚öôÔ∏è  Creando DMatrix (Versi√≥n Ligera)...\")\n",
    "# Usamos DMatrix normal, no QuantileDMatrix (consume menos RAM al crearse)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_cols)\n",
    "dtest  = xgb.DMatrix(X_test, label=y_test, feature_names=feature_cols)\n",
    "\n",
    "# Liberamos los arrays de numpy tambi√©n\n",
    "del X_train, y_train, X_test, y_test\n",
    "gc.collect()\n",
    "\n",
    "# 4. CONFIGURACI√ìN Y ENTRENAMIENTO\n",
    "try:\n",
    "    with open(\"best_hyperparameters.json\", \"r\") as f:\n",
    "        best_params = json.load(f)\n",
    "    print(\"üíé Usando par√°metros optimizados.\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Usando par√°metros manuales.\")\n",
    "    best_params = {\"learning_rate\": 0.008957827193783819, \"max_depth\": 7, \"subsample\": 0.5309661926071266, \"colsample_bytree\": 0.8548686375385406, \"min_child_weight\": 14, \"gamma\": 4.997392487608526, \"lambda\": 6.9850562385010155, \"alpha\": 0.6101433943490518}\n",
    "best_params.update({\n",
    "    'device': 'cuda',\n",
    "    'tree_method': 'hist', # 'hist' sigue funcionando con DMatrix y es r√°pido\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc'\n",
    "})\n",
    "\n",
    "print(\"üöÄ INICIANDO ENTRENAMIENTO...\")\n",
    "model = xgb.train(\n",
    "    best_params,\n",
    "    dtrain,\n",
    "    num_boost_round=10000,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    verbose_eval=500,\n",
    "    early_stopping_rounds=500\n",
    ")\n",
    "\n",
    "print(f\"üèÜ Mejor Score: {model.best_score}\")\n",
    "model.save_model(\"draft_oracle_brain_v12_final.json\")\n",
    "with open(\"model_features_v12.json\", \"w\") as f: json.dump(feature_cols, f)\n",
    "print(\"üèÅ Modelo Guardado.\")"
   ],
   "id": "e138a361a3d342ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Cargando dataset...\n",
      "‚ö° Cargando dataset pre-cocinado: draft_oracle_training_set.parquet\n",
      "üëî Aplicando L√≥gica de Head Coach (Archetypes & Synergies)...\n",
      "‚ö° Cargando Dataset desde draft_oracle_training_set.parquet...\n",
      "üìâ Comprimiendo datos a Float32...\n",
      "üß† [1/3] Calculando L√≥gica de Combate (Da√±o vs Resistencia)...\n",
      "üî¨ [2/3] Analizando Psicolog√≠a, Econom√≠a y RIESGO (V12)...\n",
      "   ‚úÖ Variable de Volatilidad (Riesgo) Calculada.\n",
      "üï∏Ô∏è  [3/3] Tejiendo Grafos de Sinergia (Mid-Jungle Links)...\n",
      "üìä Features Totales: 215\n",
      "‚úÇÔ∏è  Dividiendo Train/Test...\n",
      "   -> Liberando memoria del DataFrame (2624.89 MB)...\n",
      "‚öôÔ∏è  Creando DMatrix (Versi√≥n Ligera)...\n",
      "üíé Usando par√°metros optimizados.\n",
      "üöÄ INICIANDO ENTRENAMIENTO...\n",
      "[0]\tTest-auc:0.55115\n",
      "[500]\tTest-auc:0.58040\n",
      "[1000]\tTest-auc:0.59954\n",
      "[1500]\tTest-auc:0.61702\n",
      "[2000]\tTest-auc:0.63306\n",
      "[2500]\tTest-auc:0.64825\n",
      "[3000]\tTest-auc:0.66284\n",
      "[3500]\tTest-auc:0.67549\n",
      "[4000]\tTest-auc:0.68813\n",
      "[4500]\tTest-auc:0.70007\n",
      "[5000]\tTest-auc:0.71101\n",
      "[5500]\tTest-auc:0.72099\n",
      "[6000]\tTest-auc:0.73040\n",
      "[6500]\tTest-auc:0.73920\n",
      "[7000]\tTest-auc:0.74742\n",
      "[7500]\tTest-auc:0.75510\n",
      "[8000]\tTest-auc:0.76180\n",
      "[8500]\tTest-auc:0.76837\n",
      "[9000]\tTest-auc:0.77425\n",
      "[9500]\tTest-auc:0.77963\n",
      "[9999]\tTest-auc:0.78488\n",
      "üèÜ Mejor Score: 0.7848773737578407\n",
      "üèÅ Modelo Guardado.\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
