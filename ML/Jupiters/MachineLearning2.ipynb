{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "\n",
    "MASTER_FILE = \"draft_oracle_master_data.parquet\"\n",
    "FEATURE_FILE = \"draft_oracle_feature_store.parquet\"\n",
    "TRAIN_SET_FILE = \"draft_oracle_training_set.parquet\"\n",
    "MODEL_FILE = \"draft_oracle_brain.json\""
   ],
   "id": "45d5ceb5e75e405a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def enrich_combat_logic(df):\n",
    "    print(\"Calculando Lógica de Combate (Damage Profile & Counters)...\")\n",
    "\n",
    "    sides = [\"blue\", \"red\"]\n",
    "\n",
    "    for side in sides:\n",
    "\n",
    "        magic_cols = [c for c in df.columns if f\"{side}_\" in c and (\"stat_magic_dmg\" in c or \"avg_magic_dmg\" in c)]\n",
    "        phys_cols  = [c for c in df.columns if f\"{side}_\" in c and (\"stat_phys_dmg\" in c or \"avg_phys_dmg\" in c)]\n",
    "\n",
    "        true_cols  = [c for c in df.columns if f\"{side}_\" in c and (\"stat_true_dmg\" in c or \"avg_true_dmg\" in c)]\n",
    "\n",
    "\n",
    "        tank_cols  = [c for c in df.columns if f\"{side}_\" in c and \"stat_mitigated\" in c]\n",
    "        heal_cols  = [c for c in df.columns if f\"{side}_\" in c and \"stat_heal\" in c]\n",
    "        cc_cols    = [c for c in df.columns if f\"{side}_\" in c and \"stat_hard_cc\" in c]\n",
    "\n",
    "\n",
    "        total_magic = pl.sum_horizontal(magic_cols) if magic_cols else pl.lit(0)\n",
    "        total_phys  = pl.sum_horizontal(phys_cols) if phys_cols else pl.lit(0)\n",
    "        total_true  = pl.sum_horizontal(true_cols) if true_cols else pl.lit(0)\n",
    "        total_tank  = pl.sum_horizontal(tank_cols) if tank_cols else pl.lit(0)\n",
    "        total_heal  = pl.sum_horizontal(heal_cols) if heal_cols else pl.lit(0)\n",
    "        total_cc    = pl.sum_horizontal(cc_cols) if cc_cols else pl.lit(0)\n",
    "\n",
    "\n",
    "        df = df.with_columns([\n",
    "            total_magic.fill_null(0).alias(f\"{side}_total_magic_dmg\"),\n",
    "            total_phys.fill_null(0).alias(f\"{side}_total_phys_dmg\"),\n",
    "            total_true.fill_null(0).alias(f\"{side}_total_true_dmg\"),\n",
    "            total_tank.fill_null(0).alias(f\"{side}_total_tankiness\"),\n",
    "            total_heal.fill_null(0).alias(f\"{side}_total_sustain\"),\n",
    "            total_cc.fill_null(0).alias(f\"{side}_total_cc\")\n",
    "        ])\n",
    "\n",
    "\n",
    "        total_dmg = pl.col(f\"{side}_total_magic_dmg\") + pl.col(f\"{side}_total_phys_dmg\") + pl.col(f\"{side}_total_true_dmg\") + 1\n",
    "        df = df.with_columns(\n",
    "            (pl.col(f\"{side}_total_magic_dmg\") / total_dmg).alias(f\"{side}_magic_dmg_ratio\")\n",
    "        )\n",
    "\n",
    "\n",
    "    df = df.with_columns([\n",
    "\n",
    "        ((pl.col(\"blue_total_magic_dmg\") + pl.col(\"blue_total_true_dmg\")) / (pl.col(\"red_total_tankiness\") + 1)).alias(\"blue_shred_efficiency\"),\n",
    "        ((pl.col(\"red_total_magic_dmg\") + pl.col(\"red_total_true_dmg\")) / (pl.col(\"blue_total_tankiness\") + 1)).alias(\"red_shred_efficiency\"),\n",
    "\n",
    "\n",
    "        ((pl.col(\"blue_total_phys_dmg\") + pl.col(\"blue_total_magic_dmg\")) / (pl.col(\"red_total_sustain\") + 1000)).alias(\"blue_anti_sustain_burst\"),\n",
    "        ((pl.col(\"red_total_phys_dmg\") + pl.col(\"red_total_magic_dmg\")) / (pl.col(\"blue_total_sustain\") + 1000)).alias(\"red_anti_sustain_burst\")\n",
    "    ])\n",
    "\n",
    "    blue_volatility = sum([pl.col(f\"blue_{role}_var_gold_volatility\").fill_null(0) for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "    red_volatility  = sum([pl.col(f\"red_{role}_var_gold_volatility\").fill_null(0)  for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (blue_volatility - red_volatility).alias(\"diff_team_volatility\")\n",
    "    )\n",
    "\n",
    "    return df"
   ],
   "id": "e9ca457788af9bf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def assemble_and_clean_dataset_ultimate():\n",
    "    print(\"REGENERANDO DATASET V4.2 (Incluyendo Risk & Volatility)...\")\n",
    "\n",
    "\n",
    "    df_features = pl.read_parquet(FEATURE_FILE)\n",
    "\n",
    "\n",
    "    master_full = pl.read_parquet(MASTER_FILE)\n",
    "    df_matches = master_full.select([\n",
    "        \"game_id\", \"region\", \"patch\", \"duration\", \"target\",\n",
    "        \"champ_id\", \"position\", \"side\"\n",
    "    ])\n",
    "    del master_full\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"   Pegando Stats + Estilos + Riesgo...\")\n",
    "    enriched = df_matches.join(\n",
    "        df_features,\n",
    "        on=[\"champ_id\", \"position\", \"region\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    print(\"   Pivotando a formato Wide...\")\n",
    "\n",
    "    enriched = enriched.with_columns([\n",
    "        pl.when(pl.col(\"side\") == 100).then(pl.lit(\"blue\")).otherwise(pl.lit(\"red\")).alias(\"side_str\")\n",
    "    ])\n",
    "    enriched = enriched.with_columns(\n",
    "        (pl.col(\"side_str\") + \"_\" + pl.col(\"position\")).alias(\"pivot_col\")\n",
    "    )\n",
    "\n",
    "\n",
    "    cols_to_pivot = [\n",
    "        c for c in df_features.columns\n",
    "        if c.startswith(\"stat_\")\n",
    "        or c.startswith(\"avg_\")\n",
    "        or c.startswith(\"z_style_\")\n",
    "        or c.startswith(\"var_\")\n",
    "    ]\n",
    "    cols_to_pivot.append(\"champ_id\")\n",
    "\n",
    "    wide_df = enriched.pivot(\n",
    "        values=cols_to_pivot,\n",
    "        index=[\"game_id\", \"target\", \"region\", \"patch\"],\n",
    "        columns=\"pivot_col\",\n",
    "        aggregate_function=\"first\"\n",
    "    )\n",
    "\n",
    "    print(\"   Normalizando nombres...\")\n",
    "    new_names = {}\n",
    "    for col in wide_df.columns:\n",
    "        if \"blue\" in col or \"red\" in col:\n",
    "            parts = col.split(\"_\")\n",
    "            if \"blue\" in parts:\n",
    "                idx = parts.index(\"blue\")\n",
    "                team_pos = f\"{parts[idx]}_{parts[idx+1]}\"\n",
    "                stat_parts = [p for i, p in enumerate(parts) if i != idx and i != idx+1]\n",
    "                stat_name = \"_\".join(stat_parts)\n",
    "                new_names[col] = f\"{team_pos}_{stat_name}\"\n",
    "            elif \"red\" in parts:\n",
    "                idx = parts.index(\"red\")\n",
    "                team_pos = f\"{parts[idx]}_{parts[idx+1]}\"\n",
    "                stat_parts = [p for i, p in enumerate(parts) if i != idx and i != idx+1]\n",
    "                stat_name = \"_\".join(stat_parts)\n",
    "                new_names[col] = f\"{team_pos}_{stat_name}\"\n",
    "\n",
    "    wide_df = wide_df.rename(new_names)\n",
    "\n",
    "    print(f\"   Dataset V4.2 Guardado: {wide_df.shape}\")\n",
    "    wide_df.write_parquet(TRAIN_SET_FILE)\n",
    "    return wide_df\n",
    "\n",
    "\n",
    "df = assemble_and_clean_dataset_ultimate()"
   ],
   "id": "1fc132fb4b451638",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_interaction_matrices(df_master):\n",
    "    print(\"Construyendo Cerebro Táctico (Sinergias y Counters)...\")\n",
    "\n",
    "\n",
    "    matches = df_master.lazy().select([\n",
    "        \"game_id\", \"side\", \"champ_id\", \"position\",\n",
    "        pl.col(\"target\").alias(\"win\")\n",
    "    ])\n",
    "\n",
    "    print(\"   -> Calculando pares de aliados ganadores...\")\n",
    "    synergy = (\n",
    "        matches.join(matches, on=[\"game_id\", \"side\"])\n",
    "        .filter(pl.col(\"champ_id\") != pl.col(\"champ_id_right\"))\n",
    "        .group_by([\"champ_id\", \"champ_id_right\"])\n",
    "        .agg([\n",
    "            pl.col(\"win\").mean().alias(\"syn_winrate\"),\n",
    "            pl.count().alias(\"matches\")\n",
    "        ])\n",
    "        .filter(pl.col(\"matches\") > 50)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    print(\"   -> Calculando matchups directos...\")\n",
    "    counters = (\n",
    "        matches.join(matches, on=\"game_id\")\n",
    "        .filter(pl.col(\"side\") != pl.col(\"side_right\"))\n",
    "        .filter(pl.col(\"position\") == pl.col(\"position_right\"))\n",
    "        .group_by([\"champ_id\", \"champ_id_right\"])\n",
    "        .agg([\n",
    "            pl.col(\"win\").mean().alias(\"counter_winrate\"),\n",
    "            pl.count().alias(\"matches\")\n",
    "        ])\n",
    "        .filter(pl.col(\"matches\") > 50)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    return synergy, counters\n",
    "\n",
    "def assemble_and_clean_dataset_ultimate():\n",
    "    print(\"REGENERANDO DATASET V4.3 (FIX DEFINITIVO)...\")\n",
    "\n",
    "\n",
    "    df_features = pl.read_parquet(FEATURE_FILE)\n",
    "\n",
    "\n",
    "    master_full = pl.read_parquet(MASTER_FILE)\n",
    "    df_matches = master_full.select([\n",
    "        \"game_id\", \"region\", \"patch\", \"duration\", \"target\",\n",
    "        \"champ_id\", \"position\", \"side\"\n",
    "    ])\n",
    "    del master_full\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"   Pegando Todo el ADN...\")\n",
    "    enriched = df_matches.join(\n",
    "        df_features,\n",
    "        on=[\"champ_id\", \"position\", \"region\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    print(\"   Pivotando a formato Wide...\")\n",
    "\n",
    "    enriched = enriched.with_columns([\n",
    "        pl.when(pl.col(\"side\") == 100).then(pl.lit(\"blue\")).otherwise(pl.lit(\"red\")).alias(\"side_str\")\n",
    "    ])\n",
    "    enriched = enriched.with_columns(\n",
    "        (pl.col(\"side_str\") + \"_\" + pl.col(\"position\")).alias(\"pivot_col\")\n",
    "    )\n",
    "\n",
    "\n",
    "    cols_to_pivot = [\n",
    "        c for c in df_features.columns\n",
    "        if c.startswith(\"stat_\")\n",
    "        or c.startswith(\"avg_\")\n",
    "        or c.startswith(\"z_style_\")\n",
    "        or c.startswith(\"var_\")\n",
    "    ]\n",
    "    cols_to_pivot.append(\"champ_id\")\n",
    "\n",
    "    wide_df = enriched.pivot(\n",
    "        values=cols_to_pivot,\n",
    "        index=[\"game_id\", \"target\", \"region\", \"patch\"],\n",
    "        columns=\"pivot_col\",\n",
    "        aggregate_function=\"first\"\n",
    "    )\n",
    "\n",
    "    print(\"   Normalizando nombres...\")\n",
    "    new_names = {}\n",
    "    for col in wide_df.columns:\n",
    "        if \"blue\" in col or \"red\" in col:\n",
    "            parts = col.split(\"_\")\n",
    "            if \"blue\" in parts:\n",
    "                idx = parts.index(\"blue\")\n",
    "                team_pos = f\"{parts[idx]}_{parts[idx+1]}\"\n",
    "                stat_parts = [p for i, p in enumerate(parts) if i != idx and i != idx+1]\n",
    "                stat_name = \"_\".join(stat_parts)\n",
    "                new_names[col] = f\"{team_pos}_{stat_name}\"\n",
    "            elif \"red\" in parts:\n",
    "                idx = parts.index(\"red\")\n",
    "                team_pos = f\"{parts[idx]}_{parts[idx+1]}\"\n",
    "                stat_parts = [p for i, p in enumerate(parts) if i != idx and i != idx+1]\n",
    "                stat_name = \"_\".join(stat_parts)\n",
    "                new_names[col] = f\"{team_pos}_{stat_name}\"\n",
    "\n",
    "    wide_df = wide_df.rename(new_names)\n",
    "\n",
    "    print(f\"   Dataset V4.3 Guardado: {wide_df.shape}\")\n",
    "    wide_df.write_parquet(TRAIN_SET_FILE)\n",
    "    return wide_df\n",
    "\n",
    "\n",
    "df = assemble_and_clean_dataset_ultimate()"
   ],
   "id": "818c19c27d6c84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def enrich_critical_synergies(df):\n",
    "    print(\"Tejiendo la Red de Sinergias Críticas (Graph Theory)...\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        synergy_matrix = pl.read_parquet(\"draft_oracle_synergy_matrix.parquet\")\n",
    "    except:\n",
    "        print(\"No se encontró la matriz de sinergia. Saltando paso de grafos.\")\n",
    "        return df\n",
    "\n",
    "\n",
    "    critical_pairs = [\n",
    "        (\"MIDDLE\", \"JUNGLE\", \"syn_mid_jg\"),\n",
    "        (\"BOTTOM\", \"UTILITY\", \"syn_bot_duo\"),\n",
    "        (\"TOP\", \"JUNGLE\", \"syn_top_jg\"),\n",
    "    ]\n",
    "\n",
    "    sides = [\"blue\", \"red\"]\n",
    "\n",
    "    for side in sides:\n",
    "        for role1, role2, feat_name in critical_pairs:\n",
    "            col_id1 = f\"{side}_{role1}_champ_id\"\n",
    "            col_id2 = f\"{side}_{role2}_champ_id\"\n",
    "\n",
    "\n",
    "            if col_id1 not in df.columns or col_id2 not in df.columns:\n",
    "                continue\n",
    "\n",
    "            temp_syn = synergy_matrix.select([\n",
    "                pl.col(\"champ_id\").alias(col_id1),\n",
    "                pl.col(\"champ_id_right\").alias(col_id2),\n",
    "                pl.col(\"syn_winrate\").alias(f\"{side}_{feat_name}\")\n",
    "            ])\n",
    "\n",
    "            df = df.join(temp_syn, on=[col_id1, col_id2], how=\"left\")\n",
    "            df = df.with_columns(pl.col(f\"{side}_{feat_name}\").fill_null(0.5))\n",
    "\n",
    "\n",
    "    if \"blue_syn_bot_duo\" in df.columns and \"red_syn_bot_duo\" in df.columns:\n",
    "        df = df.with_columns((pl.col(\"blue_syn_bot_duo\") - pl.col(\"red_syn_bot_duo\")).alias(\"gap_syn_bot_duo\"))\n",
    "    if \"blue_syn_mid_jg\" in df.columns and \"red_syn_mid_jg\" in df.columns:\n",
    "        df = df.with_columns((pl.col(\"blue_syn_mid_jg\") - pl.col(\"red_syn_mid_jg\")).alias(\"gap_syn_mid_jg\"))\n",
    "\n",
    "    return df\n"
   ],
   "id": "3cbe1ea4c54315eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_and_prep_data():\n",
    "    import os\n",
    "    if os.path.exists(TRAIN_SET_FILE):\n",
    "        print(f\"Cargando dataset pre-cocinado: {TRAIN_SET_FILE}\")\n",
    "        df = pl.read_parquet(TRAIN_SET_FILE)\n",
    "    else:\n",
    "\n",
    "        raise FileNotFoundError(\"Genera primero el training_set con el código anterior.\")\n",
    "\n",
    "    print(\"Aplicando Lógica de Head Coach (Archetypes & Synergies)...\")\n",
    "\n",
    "\n",
    "    sides = [\"blue\", \"red\"]\n",
    "    new_cols = []\n",
    "\n",
    "    for side in sides:\n",
    "        enemy_side = \"red\" if side == \"blue\" else \"blue\"\n",
    "\n",
    "\n",
    "        dmg_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_dpm\" in c]\n",
    "        mitigated_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_mitigated\" in c]\n",
    "        heal_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_heal\" in c]\n",
    "\n",
    "\n",
    "        cc_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_hard_cc\" in c]\n",
    "        vision_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_vision\" in c]\n",
    "\n",
    "\n",
    "        mid_roam = f\"{side}_middle_stat_roam_kills\"\n",
    "        jg_roam = f\"{side}_jungle_stat_roam_kills\"\n",
    "\n",
    "\n",
    "        team_cc = pl.sum_horizontal(cc_cols)\n",
    "        team_tankiness = pl.sum_horizontal(mitigated_cols)\n",
    "        engage_score = ((team_cc * team_tankiness) / 10000).alias(f\"{side}_archetype_engage\")\n",
    "        new_cols.append(engage_score)\n",
    "\n",
    "\n",
    "        sustain_score = (pl.sum_horizontal(heal_cols) + team_tankiness).alias(f\"{side}_archetype_sustain\")\n",
    "        new_cols.append(sustain_score)\n",
    "\n",
    "\n",
    "        vision_score = pl.sum_horizontal(vision_cols)\n",
    "        pick_potential = (vision_score * team_cc).alias(f\"{side}_archetype_pick\")\n",
    "        new_cols.append(pick_potential)\n",
    "\n",
    "\n",
    "        if mid_roam in df.columns and jg_roam in df.columns:\n",
    "            mid_jg_syn = (pl.col(mid_roam) + pl.col(jg_roam)).alias(f\"{side}_syn_mid_jungle\")\n",
    "            new_cols.append(mid_jg_syn)\n",
    "\n",
    "        prio_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_lane_priority_score\" in c]\n",
    "        rel_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_reliability_index\" in c]\n",
    "        early_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_wr_early\" in c]\n",
    "        late_cols = [c for c in df.columns if f\"{side}_\" in c and \"stat_wr_late\" in c]\n",
    "\n",
    "\n",
    "        if len(prio_cols) > 0:\n",
    "\n",
    "            new_cols.append(pl.sum_horizontal(prio_cols).alias(f\"{side}_strat_total_priority\"))\n",
    "\n",
    "\n",
    "            new_cols.append(pl.mean_horizontal(rel_cols).alias(f\"{side}_strat_avg_reliability\"))\n",
    "\n",
    "\n",
    "            new_cols.append(pl.mean_horizontal(early_cols).alias(f\"{side}_strat_early_power\"))\n",
    "            new_cols.append(pl.mean_horizontal(late_cols).alias(f\"{side}_strat_late_power\"))\n",
    "\n",
    "\n",
    "    blue_cc = pl.sum_horizontal([c for c in df.columns if \"blue_\" in c and \"stat_hard_cc\" in c])\n",
    "    red_cc = pl.sum_horizontal([c for c in df.columns if \"red_\" in c and \"stat_hard_cc\" in c])\n",
    "\n",
    "    blue_range = pl.sum_horizontal([c for c in df.columns if \"blue_\" in c and \"stat_dpm\" in c])\n",
    "    red_mitigation = pl.sum_horizontal([c for c in df.columns if \"red_\" in c and \"stat_mitigated\" in c])\n",
    "\n",
    "\n",
    "    new_cols.append((blue_cc - red_cc).alias(\"diff_cc_gap\"))\n",
    "\n",
    "\n",
    "    new_cols.append((blue_range / (red_mitigation + 1)).alias(\"diff_shred_potential\"))\n",
    "\n",
    "\n",
    "    df = df.with_columns(new_cols)\n",
    "    return df\n",
    "\n",
    "\n",
    "if 'load_and_prep_data' not in globals(): raise Exception(\"Ejecuta load_and_prep_data()\")\n",
    "print(\"Cargando dataset...\")\n",
    "df = load_and_prep_data()\n",
    "\n",
    "\n",
    "def enrich_combat_logic(df):\n",
    "    print(\"[1/3] Calculando Lógica de Combate (Daño vs Resistencia)...\")\n",
    "    sides = [\"blue\", \"red\"]\n",
    "    for side in sides:\n",
    "\n",
    "        magic_cols = [c for c in df.columns if f\"{side}_\" in c and (\"stat_magic_dmg\" in c or \"avg_magic_dmg\" in c)]\n",
    "        phys_cols  = [c for c in df.columns if f\"{side}_\" in c and (\"stat_phys_dmg\" in c or \"avg_phys_dmg\" in c)]\n",
    "        true_cols  = [c for c in df.columns if f\"{side}_\" in c and (\"stat_true_dmg\" in c or \"avg_true_dmg\" in c)]\n",
    "        tank_cols  = [c for c in df.columns if f\"{side}_\" in c and \"stat_mitigated\" in c]\n",
    "        heal_cols  = [c for c in df.columns if f\"{side}_\" in c and \"stat_heal\" in c]\n",
    "        cc_cols    = [c for c in df.columns if f\"{side}_\" in c and \"stat_hard_cc\" in c]\n",
    "\n",
    "\n",
    "        total_magic = pl.sum_horizontal(magic_cols) if magic_cols else pl.lit(0)\n",
    "        total_phys  = pl.sum_horizontal(phys_cols) if phys_cols else pl.lit(0)\n",
    "        total_true  = pl.sum_horizontal(true_cols) if true_cols else pl.lit(0)\n",
    "        total_tank  = pl.sum_horizontal(tank_cols) if tank_cols else pl.lit(0)\n",
    "        total_heal  = pl.sum_horizontal(heal_cols) if heal_cols else pl.lit(0)\n",
    "        total_cc    = pl.sum_horizontal(cc_cols) if cc_cols else pl.lit(0)\n",
    "\n",
    "\n",
    "        df = df.with_columns([\n",
    "            total_magic.fill_null(0).alias(f\"{side}_total_magic_dmg\"),\n",
    "            total_phys.fill_null(0).alias(f\"{side}_total_phys_dmg\"),\n",
    "            total_true.fill_null(0).alias(f\"{side}_total_true_dmg\"),\n",
    "            total_tank.fill_null(0).alias(f\"{side}_total_tankiness\"),\n",
    "            total_heal.fill_null(0).alias(f\"{side}_total_sustain\"),\n",
    "            total_cc.fill_null(0).alias(f\"{side}_total_cc\")\n",
    "        ])\n",
    "\n",
    "\n",
    "        total_dmg = pl.col(f\"{side}_total_magic_dmg\") + pl.col(f\"{side}_total_phys_dmg\") + pl.col(f\"{side}_total_true_dmg\") + 1\n",
    "        df = df.with_columns((pl.col(f\"{side}_total_magic_dmg\") / total_dmg).alias(f\"{side}_magic_dmg_ratio\"))\n",
    "\n",
    "    df = df.with_columns([\n",
    "        ((pl.col(\"blue_total_magic_dmg\") + pl.col(\"blue_total_true_dmg\")) / (pl.col(\"red_total_tankiness\") + 1)).alias(\"blue_shred_efficiency\"),\n",
    "        ((pl.col(\"red_total_magic_dmg\") + pl.col(\"red_total_true_dmg\")) / (pl.col(\"blue_total_tankiness\") + 1)).alias(\"red_shred_efficiency\"),\n",
    "        ((pl.col(\"blue_total_phys_dmg\") + pl.col(\"blue_total_magic_dmg\")) / (pl.col(\"red_total_sustain\") + 1000)).alias(\"blue_anti_sustain_burst\"),\n",
    "        ((pl.col(\"red_total_phys_dmg\") + pl.col(\"red_total_magic_dmg\")) / (pl.col(\"blue_total_sustain\") + 1000)).alias(\"red_anti_sustain_burst\")\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "def enrich_behavioral_strategy(df):\n",
    "    print(\"[2/3] Analizando Psicología, Economía y RIESGO (V12)...\")\n",
    "    sides = [\"blue\", \"red\"]\n",
    "    for side in sides:\n",
    "\n",
    "        jg_aggro = pl.col(f\"{side}_JUNGLE_z_style_gank_heaviness\").fill_null(0)\n",
    "        lanes_aggro = (pl.col(f\"{side}_TOP_z_style_lane_dominance\").fill_null(0) +\n",
    "                       pl.col(f\"{side}_MIDDLE_z_style_lane_dominance\").fill_null(0) +\n",
    "                       pl.col(f\"{side}_BOTTOM_z_style_lane_dominance\").fill_null(0)) / 3\n",
    "        df = df.with_columns((jg_aggro * lanes_aggro).alias(f\"{side}_strat_gank_compatibility\"))\n",
    "\n",
    "\n",
    "        gold_hunger = sum([pl.col(f\"{side}_{role}_z_style_gold_hunger\").fill_null(0)\n",
    "                           for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "        df = df.with_columns(gold_hunger.alias(f\"{side}_strat_resource_friction\"))\n",
    "\n",
    "\n",
    "        invade_potential = pl.col(f\"{side}_JUNGLE_z_style_invade_pressure\").fill_null(0)\n",
    "        backup_potential = (pl.col(f\"{side}_TOP_z_style_roaming_tendency\").fill_null(0) + pl.col(f\"{side}_MIDDLE_z_style_roaming_tendency\").fill_null(0))\n",
    "        df = df.with_columns((invade_potential * backup_potential).alias(f\"{side}_strat_invade_safety\"))\n",
    "\n",
    "\n",
    "    try:\n",
    "        blue_vol = sum([pl.col(f\"blue_{role}_var_gold_volatility\").fill_null(0) for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "        red_vol  = sum([pl.col(f\"red_{role}_var_gold_volatility\").fill_null(0)  for role in [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]])\n",
    "        df = df.with_columns((blue_vol - red_vol).alias(\"diff_team_volatility\"))\n",
    "        print(\"   Variable de Volatilidad (Riesgo) Calculada.\")\n",
    "    except:\n",
    "        print(\"   No se encontraron columnas de Volatilidad. Se entrena sin factor de riesgo.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def enrich_critical_synergies(df):\n",
    "    print(\"[3/3] Tejiendo Grafos de Sinergia (Mid-Jungle Links)...\")\n",
    "    try:\n",
    "        synergy_matrix = pl.read_parquet(\"draft_oracle_synergy_matrix.parquet\")\n",
    "    except:\n",
    "        print(\"   No se encontró la matriz de sinergia.\")\n",
    "        return df\n",
    "\n",
    "    critical_pairs = [(\"MIDDLE\", \"JUNGLE\", \"syn_mid_jg\"), (\"BOTTOM\", \"UTILITY\", \"syn_bot_duo\"), (\"TOP\", \"JUNGLE\", \"syn_top_jg\")]\n",
    "    sides = [\"blue\", \"red\"]\n",
    "\n",
    "    for side in sides:\n",
    "        for role1, role2, feat_name in critical_pairs:\n",
    "            col_id1 = f\"{side}_{role1}_champ_id\"\n",
    "            col_id2 = f\"{side}_{role2}_champ_id\"\n",
    "            if col_id1 not in df.columns or col_id2 not in df.columns: continue\n",
    "\n",
    "            temp_syn = synergy_matrix.select([\n",
    "                pl.col(\"champ_id\").alias(col_id1), pl.col(\"champ_id_right\").alias(col_id2), pl.col(\"syn_winrate\").alias(f\"{side}_{feat_name}\")\n",
    "            ])\n",
    "            df = df.join(temp_syn, on=[col_id1, col_id2], how=\"left\")\n",
    "            df = df.with_columns(pl.col(f\"{side}_{feat_name}\").fill_null(0.5))\n",
    "\n",
    "    if \"blue_syn_mid_jg\" in df.columns and \"red_syn_mid_jg\" in df.columns:\n",
    "        df = df.with_columns((pl.col(\"blue_syn_mid_jg\") - pl.col(\"red_syn_mid_jg\")).alias(\"gap_syn_mid_jg\"))\n",
    "    return df\n",
    "\n",
    "\n",
    "TRAIN_FILE = \"draft_oracle_training_set.parquet\"\n",
    "print(f\"Cargando Dataset desde {TRAIN_FILE}...\")\n",
    "\n",
    "if not os.path.exists(TRAIN_FILE):\n",
    "    raise FileNotFoundError(\"Ejecuta primero el Assembler.\")\n",
    "\n",
    "\n",
    "df = pl.read_parquet(TRAIN_FILE)\n",
    "float_cols = [c for c in df.columns if df[c].dtype == pl.Float64]\n",
    "if float_cols:\n",
    "    print(\"Comprimiendo datos a Float32...\")\n",
    "    df = df.with_columns([pl.col(c).cast(pl.Float32) for c in float_cols])\n",
    "\n",
    "\n",
    "if 'enrich_combat_logic' in globals(): df = enrich_combat_logic(df)\n",
    "if 'enrich_behavioral_strategy' in globals(): df = enrich_behavioral_strategy(df)\n",
    "if 'enrich_critical_synergies' in globals(): df = enrich_critical_synergies(df)\n",
    "\n",
    "\n",
    "roles = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]\n",
    "duel_stats = [\"stat_winrate\", \"stat_gpm\", \"stat_dpm\", \"z_style_lane_dominance\"]\n",
    "new_cols = []\n",
    "for role in roles:\n",
    "    for stat in duel_stats:\n",
    "        col_blue, col_red = f\"blue_{role}_{stat}\", f\"red_{role}_{stat}\"\n",
    "        if col_blue in df.columns and col_red in df.columns:\n",
    "            new_cols.append((pl.col(col_blue) - pl.col(col_red)).alias(f\"duel_{role}_{stat}\"))\n",
    "if new_cols: df = df.with_columns(new_cols)\n",
    "\n",
    "\n",
    "feature_cols = [c for c in df.columns if (\n",
    "    \"stat_\" in c or \"rune_\" in c or \"archetype_\" in c or \"gap_\" in c or \"duel_\" in c or\n",
    "    \"_total_\" in c or \"_ratio\" in c or \"_efficiency\" in c or \"_burst\" in c or\n",
    "    \"z_style_\" in c or \"_strat_\" in c or \"_syn_\" in c or \"diff_team_volatility\" in c\n",
    ") and c not in [\"target\", \"split_key\", \"game_id\"] and \"win\" not in c]\n",
    "\n",
    "print(f\"Features Totales: {len(feature_cols)}\")\n",
    "\n",
    "print(\"Dividiendo Train/Test...\")\n",
    "df = df.with_columns(pl.Series(name=\"split_key\", values=np.random.rand(df.height)).cast(pl.Float32))\n",
    "\n",
    "\n",
    "X_train = df.filter(pl.col(\"split_key\") < 0.95).select(feature_cols).to_numpy()\n",
    "y_train = df.filter(pl.col(\"split_key\") < 0.95).select(\"target\").to_numpy().flatten()\n",
    "X_test  = df.filter(pl.col(\"split_key\") >= 0.95).select(feature_cols).to_numpy()\n",
    "y_test  = df.filter(pl.col(\"split_key\") >= 0.95).select(\"target\").to_numpy().flatten()\n",
    "\n",
    "print(f\"   -> Liberando memoria del DataFrame ({df.estimated_size() / 1024**2:.2f} MB)...\")\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "print(\"Creando DMatrix (Versión Ligera)...\")\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_cols)\n",
    "dtest  = xgb.DMatrix(X_test, label=y_test, feature_names=feature_cols)\n",
    "\n",
    "\n",
    "del X_train, y_train, X_test, y_test\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"best_hyperparameters.json\", \"r\") as f:\n",
    "        best_params = json.load(f)\n",
    "    print(\"Usando parámetros optimizados.\")\n",
    "except:\n",
    "    print(\"Usando parámetros manuales.\")\n",
    "    best_params = {\"learning_rate\": 0.008957827193783819, \"max_depth\": 7, \"subsample\": 0.5309661926071266, \"colsample_bytree\": 0.8548686375385406, \"min_child_weight\": 14, \"gamma\": 4.997392487608526, \"lambda\": 6.9850562385010155, \"alpha\": 0.6101433943490518}\n",
    "best_params.update({\n",
    "    'device': 'cuda',\n",
    "    'tree_method': 'hist',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc'\n",
    "})\n",
    "\n",
    "print(\"INICIANDO ENTRENAMIENTO...\")\n",
    "model = xgb.train(\n",
    "    best_params,\n",
    "    dtrain,\n",
    "    num_boost_round=10000,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    verbose_eval=500,\n",
    "    early_stopping_rounds=500\n",
    ")\n",
    "\n",
    "print(f\"Mejor Score: {model.best_score}\")\n",
    "model.save_model(\"draft_oracle_brain_v12_final.json\")\n",
    "with open(\"model_features_v12.json\", \"w\") as f: json.dump(feature_cols, f)\n",
    "print(\"Modelo Guardado.\")"
   ],
   "id": "e138a361a3d342ad",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
